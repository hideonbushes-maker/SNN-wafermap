# -*- coding: utf-8 -*-
"""Wafer2Spike_Structured_Notebook.ipynb(05.15. BatchNorm 없애고, timestep 값 변경 - 정확도: 0.9446, 샘플당 에너지: 7.002mJ)의 사본

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oKhBVeEWEkIm_Obetpvmf0QvOZE-9l1q

BatchNorm을 사용하면 안되는 이유

 SNN은 각 타임스텝마다 membrane potential(state)이 누적되면서 스파이크를 만들어 내는데, 여기에 배치 단위 정규화를 넣으면 시퀀스 전체의 전압 흐름이 일관되지 않게 바뀔 수 있습니다.

 일반 신경망은 model.eval() 시 배치 통계를 고정해서 쓰지만, SNN에서는 상태가 계속 바뀌기 때문에 BatchNorm의 추정 통계(running mean/var)가 실제 분포와 잘 안 맞아 학습·추론 간 불일치가 커질 수 있습니다.

Method 1 : GroupNorm 사용 -- kaiming he. 일반적인 CNN에 적용되는 방식

Method 2 : MPBN 사용 -- Yufei-guo. SNN 특화 정규화 방식
"""

# 1. Google Drive 마운트
from google.colab import drive
drive.mount('/content/drive')

# 2. 필요한 라이브러리 임포트
import pandas as pd

# 3. Wafer 데이터셋 로드
# 파일 위치가 "/MyDrive/WM-811k/LSWMD.pkl"일 경우 아래와 같이 수정
df = pd.read_pickle("/content/drive/MyDrive/WM-811k/LSWMD.pkl")

# 4. 데이터 일부 확인
print("✅ Wafer dataset loaded successfully!")
print(df.head())

import torch
import torch.nn as nn
from torch.distributions.bernoulli import Bernoulli

Cg = 0.3  # Coefficient Gain for surrogate gradient

class PseudoGradSpike(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input, vth, cw):
        ctx.save_for_backward(input)
        ctx.vth = vth
        ctx.cw = cw
        return input.gt(vth).float()

    @staticmethod
    def backward(ctx, grad_output):
        input, = ctx.saved_tensors
        vth = ctx.vth
        cw = ctx.cw
        grad_input = grad_output.clone()
        spike_pseudo_grad = abs(input - vth) < cw
        return Cg * grad_input * spike_pseudo_grad.float(), None, None


class PseudoGradSpikeWithDropout(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input, vth, cw, mask):
        ctx.save_for_backward(input)
        ctx.vth = vth
        ctx.cw = cw
        ctx.mask = mask
        return input.gt(vth).float()

    @staticmethod
    def backward(ctx, grad_output):
        input, = ctx.saved_tensors
        vth = ctx.vth
        cw = ctx.cw
        mask = ctx.mask
        grad_input = grad_output.clone()
        spike_pseudo_grad = abs(input - vth) < cw
        spike_pseudo_grad[mask==0] = 0
        return Cg * grad_input * spike_pseudo_grad.float(), None, None, None


class CurrentBasedLIF(nn.Module):
    def __init__(self, func_v, pseudo_grad_ops, param):
        super(CurrentBasedLIF, self).__init__()
        self.func_v = func_v
        self.pseudo_grad_ops = pseudo_grad_ops
        self.w_scdecay, self.w_vdecay, self.vth, self.cw = param

    def forward(self, input_data, state):
        pre_spike, pre_current, pre_volt = state
        current = self.w_scdecay * pre_current + self.func_v(input_data)
        volt = self.w_vdecay * pre_volt * (1. - pre_spike) + current
        output = self.pseudo_grad_ops(volt, self.vth, self.cw)
        return output, (output, current, volt)


class CurrentBasedLIFWithDropout(nn.Module):
    def __init__(self, func_v, pseudo_grad_ops, param):
        super(CurrentBasedLIFWithDropout, self).__init__()
        self.func_v = func_v
        self.pseudo_grad_ops = pseudo_grad_ops
        self.w_scdecay, self.w_vdecay, self.vth, self.cw = param

    def forward(self, input_data, state, mask, train):
        pre_spike, pre_current, pre_volt = state
        current = self.w_scdecay * pre_current + self.func_v(input_data)
        if train is True:
            current = current * mask
        volt = self.w_vdecay * pre_volt * (1. - pre_spike) + current
        output = self.pseudo_grad_ops(volt, self.vth, self.cw, mask)
        return output, (output, current, volt)


class Wafer2Spike(nn.Module):
    def __init__(self, numClasses, dropout_fc, spike_ts, device, params):
        super(Wafer2Spike, self).__init__()
        self.device = device
        self.spike_ts = spike_ts
        self.dropout_fc = dropout_fc
        self.scdecay, self.vdecay, self.vth, self.cw = params

        pseudo_grad_ops = PseudoGradSpike.apply
        pseudo_grad_ops_with_dropout = PseudoGradSpikeWithDropout.apply

        self.conv_spk_enc_w_vdecay = nn.Parameter(torch.ones(1, 64, 30, 30, device=self.device) * self.vdecay)
        self.conv_spk_enc_w_scdecay = nn.Parameter(torch.ones(1, 64, 30, 30, device=self.device) * self.scdecay)

        self.Spk_conv1_w_vdecay = nn.Parameter(torch.ones(1, 64, 12, 12, device=self.device) * self.vdecay)
        self.Spk_conv1_w_scdecay = nn.Parameter(torch.ones(1, 64, 12, 12, device=self.device) * self.scdecay)

        self.Spk_conv2_w_vdecay = nn.Parameter(torch.ones(1, 64, 3, 3, device=self.device) * self.vdecay)
        self.Spk_conv2_w_scdecay = nn.Parameter(torch.ones(1, 64, 3, 3, device=self.device) * self.scdecay)

        self.Spk_fc_w_vdecay = nn.Parameter(torch.ones(1, 256*9, device=self.device) * self.vdecay)
        self.Spk_fc_w_scdecay = nn.Parameter(torch.ones(1, 256*9, device=self.device) * self.scdecay)

        self.w_t = nn.Parameter(torch.ones((self.spike_ts), device=self.device) / self.spike_ts)

        self.conv_spk_enc = CurrentBasedLIF(nn.Conv2d(1, 64, (7, 7), stride=1, bias=True), pseudo_grad_ops,
        [self.conv_spk_enc_w_scdecay, self.conv_spk_enc_w_vdecay, self.vth, self.cw])

        self.Spk_conv1 = CurrentBasedLIF(nn.Conv2d(64, 64, (7, 7), stride=2, bias=True), pseudo_grad_ops,
        [self.Spk_conv1_w_scdecay, self.Spk_conv1_w_vdecay, self.vth, self.cw])

        self.Spk_conv2 = CurrentBasedLIF(nn.Conv2d(64, 64, (7, 7), stride=2, bias=True), pseudo_grad_ops,
        [self.Spk_conv2_w_scdecay, self.Spk_conv2_w_vdecay, self.vth, self.cw])

        self.Spk_fc = CurrentBasedLIFWithDropout(nn.Linear(64*9, 256*9, bias=True), pseudo_grad_ops_with_dropout,
        [self.Spk_fc_w_scdecay, self.Spk_fc_w_vdecay, self.vth, self.cw])

        self.nonSpk_fc = nn.Linear(256*9, numClasses)

    def forward(self, input_data, states):
        batch_size = input_data.shape[0]
        output_spikes = []

        conv_spk_enc_state, Spk_conv1_state, Spk_conv2_state, Spk_fc_state = states[0], states[1], states[2], states[3]

        mask_fc = Bernoulli(
            torch.full_like(torch.zeros(batch_size, 256*9, device=self.device), 1 - self.dropout_fc)
        ).sample() / (1 - self.dropout_fc)

        for step in range(self.spike_ts):
            input_spike = input_data
            conv_spk_enc_spike, conv_spk_enc_state = self.conv_spk_enc(input_spike, conv_spk_enc_state)
            Spk_conv1_spike, Spk_conv1_state = self.Spk_conv1(conv_spk_enc_spike, Spk_conv1_state)
            Spk_conv2_spike, Spk_conv2_state = self.Spk_conv2(Spk_conv1_spike, Spk_conv2_state)

            flattened_spike = Spk_conv2_spike.view(batch_size, -1)
            Spk_fc_spike, Spk_fc_state = self.Spk_fc(flattened_spike, Spk_fc_state, mask_fc, self.training)
            nonSpk_fc_output = self.nonSpk_fc(Spk_fc_spike)
            output_spikes += [nonSpk_fc_output * self.w_t[step]]

        return torch.stack(output_spikes).sum(dim=0)


class CurrentBasedSNN(nn.Module):
    def __init__(self, numClasses, dropout_fc, spike_ts, device, params):
        super(CurrentBasedSNN, self).__init__()
        self.device = device
        self.wafer2spike = Wafer2Spike(numClasses, dropout_fc, spike_ts, device, params)

    def forward(self, input_data):
        batch_size = input_data.shape[0]

        conv_spk_enc_state = tuple(torch.zeros(batch_size, 64, 30, 30, device=self.device) for _ in range(3))
        Spk_conv1_state = tuple(torch.zeros(batch_size, 64, 12, 12, device=self.device) for _ in range(3))
        Spk_conv2_state = tuple(torch.zeros(batch_size, 64, 3, 3, device=self.device) for _ in range(3))
        Spk_fc_state = tuple(torch.zeros(batch_size, 256*9, device=self.device) for _ in range(3))

        states = (conv_spk_enc_state, Spk_conv1_state, Spk_conv2_state, Spk_fc_state)
        return self.wafer2spike(input_data, states)

# ─── Cell 2: Wafer 데이터 로드 → 증강 → NumPy/OpenCV 전처리 → Tensor 변환 → DataLoader ───

import os, random
import numpy as np
import pandas as pd
import cv2
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from sklearn.model_selection import train_test_split

# 0) 원하는 Split 비율 설정 (합 = 1.0)
TRAIN_RATIO = 0.6   # 논문대로 6:1:3
VAL_RATIO   = 0.1
TEST_RATIO  = 0.3

# 1) 시드 고정
seed = 42
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)

# 2) DataFrame 로드
df = pd.read_pickle("/content/drive/MyDrive/WM-811k/LSWMD.pkl")

# 3) try/except 로 레이블 안전 추출
trte = []
for j in df["trianTestLabel"]:
    try:    trte.append(j[0][0])
    except: trte.append(np.nan)
df["trianTestLabel"] = trte

ft = []
for j in df["failureType"]:
    try:    ft.append(j[0][0])
    except: ft.append(np.nan)
df["failureType"] = ft

# 4) 문자열 → 숫자 매핑
map_type = {
    'Center':0,'Donut':1,'Edge-Loc':2,'Edge-Ring':3,
    'Loc':4,'Random':5,'Scratch':6,'Near-full':7,'none':8
}
map_tt = {'Training':0,'Test':1}
df["failureNum"]   = df["failureType"].map(map_type)
df["trainTestNum"] = df["trianTestLabel"].map(map_tt)

# 5) 유효 레이블만 필터링
df = df[df["failureNum"].notna() & df["trainTestNum"].notna()].reset_index(drop=True)
df["failureNum"]   = df["failureNum"].astype(int)
df["trainTestNum"] = df["trainTestNum"].astype(int)

# 6) Training 샘플만 추출
df_train = df[df["trainTestNum"] == 0].reset_index(drop=True)

# 7) Stratified Split: train : temp = TRAIN_RATIO : (1 - TRAIN_RATIO)
test_size1 = 1.0 - TRAIN_RATIO
X = df_train["waferMap"].values
y = df_train["failureNum"].values
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y,
    test_size=test_size1,
    stratify=y,
    random_state=seed
)

#    temp를 VAL_RATIO/(VAL_RATIO+TEST_RATIO) : TEST_RATIO/(VAL_RATIO+TEST_RATIO) 로 나눠서
#    val : test = VAL_RATIO : TEST_RATIO 비율을 맞춘다
test_size2 = TEST_RATIO / (VAL_RATIO + TEST_RATIO)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp,
    test_size=test_size2,
    stratify=y_temp,
    random_state=seed
)

# 8) 클래스 3만 fold=1 증강
def rot_aug(img):
    ang = random.randint(0,360)
    img_n = img / img.max()
    M = cv2.getRotationMatrix2D((18,18), ang, 1.0)
    return cv2.warpAffine(img_n, M, (36,36))

X_train_aug = list(X_train)
y_train_aug = list(y_train)
idxs3 = np.where(np.array(y_train)==3)[0]
random.shuffle(idxs3)
for ix in idxs3[:3884]:
    for a in np.unique([rot_aug(X_train[ix])], axis=0):
        X_train_aug.append(a)
        y_train_aug.append(3)

# 9) NumPy/OpenCV 전처리: (N,36,36) float32
def preprocess_images(arrays):
    out = []
    for im in arrays:
        im_n = im / im.max()
        im_r = cv2.resize(im_n, (36,36), interpolation=cv2.INTER_CUBIC)
        out.append(im_r)
    return np.stack(out).astype("float32")

wafer_tr_np  = preprocess_images(X_train_aug)
wafer_val_np = preprocess_images(X_val)
wafer_te_np  = preprocess_images(X_test)

# 10) ToTensor + Normalize → permute → 채널 추가
tf = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.2999,), (0.19235,))
])
wafer_tr_data  = tf(wafer_tr_np).permute(1,0,2)[:,None,:,:]
wafer_val_data = tf(wafer_val_np).permute(1,0,2)[:,None,:,:]
wafer_te_data  = tf(wafer_te_np).permute(1,0,2)[:,None,:,:]

train_labels = torch.tensor(y_train_aug, dtype=torch.long)
val_labels   = torch.tensor(y_val,       dtype=torch.long)
te_labels    = torch.tensor(y_test,      dtype=torch.long)

class WaferDataset(Dataset):
    def __init__(self, data, labels):
        self.data, self.labels = data, labels
    def __len__(self):
        return len(self.labels)
    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

BATCH_SIZE   = 256
train_loader = DataLoader(WaferDataset(wafer_tr_data, train_labels),
                          batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(WaferDataset(wafer_val_data, val_labels),
                          batch_size=BATCH_SIZE, shuffle=False)
test_loader  = DataLoader(WaferDataset(wafer_te_data, te_labels),
                          batch_size=BATCH_SIZE, shuffle=False)

dataloaders = (train_loader, val_loader, test_loader)
print(f"▶️ Cell 2 완료 — train: {len(train_loader)}, val: {len(val_loader)}, test: {len(test_loader)}")

# 출력 예시
print(f"Split ratios: Train {TRAIN_RATIO*100:.0f}%, Val {VAL_RATIO*100:.0f}%, Test {TEST_RATIO*100:.0f}%")

# ─── Cell 3: 학습 함수 정의 및 모델 훈련 ───
import torch
import torch.nn as nn
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

def test_accuracy(model, loader, criterion, device, phase="Validation"):
    model.eval()
    loss_sum, correct = 0.0, 0
    with torch.no_grad():
        for data, label in loader:
            data, label = data.to(device), label.to(device)
            out = model(data)
            loss_sum += criterion(out,label).item() * data.size(0)
            correct  += (out.argmax(1)==label).sum().item()
    avg_loss = loss_sum / len(loader.dataset)
    acc      = correct  / len(loader.dataset)
    print(f"{phase} Loss: {avg_loss:.4f}, {phase} Acc: {acc:.4f}")
    model.train()

def training(network, params,
             batch_size=256, epochs=10, lr=1e-4,
             dataloaders=None, numClasses=9,
             spike_ts=10, dropout_fc=0.3):

    train_loader, val_loader, test_loader = dataloaders
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    wafer2spike_snn = network(numClasses, dropout_fc, spike_ts, device, params=params)
    model = nn.DataParallel(wafer2spike_snn.to(device))

    criterion = nn.CrossEntropyLoss()
    decays = [
        'module.wafer2spike.conv_spk_enc_w_vdecay',
        'module.wafer2spike.conv_spk_enc_w_scdecay',
        'module.wafer2spike.Spk_conv1_w_vdecay',
        'module.wafer2spike.Spk_conv1_w_scdecay',
        'module.wafer2spike.Spk_conv2_w_vdecay',
        'module.wafer2spike.Spk_conv2_w_scdecay',
        'module.wafer2spike.Spk_fc_w_vdecay',
        'module.wafer2spike.Spk_fc_w_scdecay'
    ]
    weights_ts = ['module.wafer2spike.w_t']

    decay_params = [p for n,p in model.named_parameters() if n in decays]
    params_ts    = [p for n,p in model.named_parameters() if n in weights_ts]
    weights      = [p for n,p in model.named_parameters() if n not in decays+weights_ts]

    optimizer = torch.optim.Adam(
        [{'params':weights}, {'params':decay_params}, {'params':params_ts}],
        lr=lr
    )

    for epoch in range(1, epochs+1):
        model.train()
        loss_sum, correct = 0.0, 0
        for data, label in train_loader:
            data, label = data.to(device), label.to(device)
            optimizer.zero_grad()
            out = model(data)
            loss = criterion(out, label)
            loss.backward()
            optimizer.step()
            loss_sum += loss.item() * data.size(0)
            correct  += (out.argmax(1)==label).sum().item()

        for p in decay_params:
            p.data.clamp_(min=1e-7)

        train_loss = loss_sum / len(train_loader.dataset)
        train_acc  = correct  / len(train_loader.dataset)
        print(f"Epoch {epoch}/{epochs} — Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")

        test_accuracy(model, val_loader, criterion, device, phase="Validation")

    test_accuracy(model, test_loader, criterion, device, phase="Test")

    preds, trues = [], []
    with torch.no_grad():
        for data, label in test_loader:
            data, label = data.to(device), label.to(device)
            preds.extend(model(data).argmax(1).cpu().tolist())
            trues.extend(label.cpu().tolist())

    print("\nConfusion Matrix:")
    print(confusion_matrix(trues, preds))
    print(classification_report(trues, preds))
    return model

# ▶️ 학습 실행
trained_model = training(
    network     = CurrentBasedSNN,
    params      = [0.05, 0.1, 0.08, 0.3],
    dataloaders = dataloaders
)

# DataParallel 래퍼 해제
model = trained_model.module if hasattr(trained_model, 'module') else trained_model

# ─── Cell 5: forward()만 떼서 전력 측정 ───
import time
import pynvml
import torch
from IPython.display import display

# 1) NVML 초기화 & 파워 리더 함수
pynvml.nvmlInit()
_handle = pynvml.nvmlDeviceGetHandleByIndex(0)
def get_gpu_power():
    return pynvml.nvmlDeviceGetPowerUsage(_handle) / 1000.0  # mW → W

device = next(model.parameters()).device  # 모델이 올라간 디바이스

# 2) 한 배치만 뽑아서 미리 GPU에 올려두기
batch, _ = next(iter(test_loader))
batch = batch.to(device, non_blocking=True)

# 3) idle baseline 전력 측정 (GPU 연산 대기 상태)
idle_samples = []
for _ in range(20):         # 20번 샘플링
    idle_samples.append(get_gpu_power())
    time.sleep(0.01)        # 10ms 간격
idle_power = sum(idle_samples) / len(idle_samples)

# 4) forward 전/후 전력 샘플링
torch.cuda.synchronize()
p0 = get_gpu_power()
t0 = time.time()

# 순수 연산
_ = model(batch)

torch.cuda.synchronize()
t1 = time.time()
p1 = get_gpu_power()

# 5) 에너지 계산 (W·s → J)
energy = ((p0 + p1)/2 - idle_power) * (t1 - t0)
print(f"한 배치({batch.size(0)}개) 순수 forward 에너지: {energy:.6f} J")

# 6) 샘플당 에너지
per_sample = energy / batch.size(0)
print(f"샘플당 에너지: {per_sample*1e3:.3f} mJ")

# 7) 결과 표시
print(f"  p0={p0:.3f} W, p1={p1:.3f} W, idle={idle_power:.3f} W, Δt={t1-t0:.4f} s")

import torch
import torch.nn as nn
from torch.distributions.bernoulli import Bernoulli

class FastSigmoidSurrogate(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input, vth, alpha=10.0):
        ctx.save_for_backward(input)
        ctx.vth = vth
        ctx.alpha = alpha
        # Heaviside-style forward
        return (input > vth).float()

    @staticmethod
    def backward(ctx, grad_output):
        input, = ctx.saved_tensors
        vth = ctx.vth
        alpha = ctx.alpha
        x = input - vth
        expm = torch.exp(-alpha * x)
        grad = alpha * expm / (1 + expm) ** 2
        return grad_output * grad, None, None


class CurrentBasedLIF(nn.Module):
    def __init__(self, conv_or_linear, bn_layer, surrogate, param):
        super(CurrentBasedLIF, self).__init__()
        self.layer     = conv_or_linear
        self.bn        = bn_layer
        self.surrogate = surrogate.apply
        # param = [w_scdecay, w_vdecay, vth, alpha]
        self.w_scdecay, self.w_vdecay, self.vth, self.alpha = param

    def forward(self, input_data, state):
        pre_spike, pre_current, pre_volt = state
        # 1) linear/conv → BatchNorm → ReLU
        x = self.layer(input_data)
        x = self.bn(x)
        x = torch.relu(x)
        # 2) LIF 업데이트
        current = self.w_scdecay * pre_current + x
        volt    = self.w_vdecay  * pre_volt  * (1. - pre_spike) + current
        # 3) surrogate spike generation
        output = self.surrogate(volt, self.vth, self.alpha)
        return output, (output, current, volt)


class CurrentBasedLIFWithDropout(nn.Module):
    def __init__(self, linear, bn_layer, surrogate, param):
        super(CurrentBasedLIFWithDropout, self).__init__()
        self.layer     = linear
        self.bn        = bn_layer
        self.surrogate = surrogate.apply
        # param = [w_scdecay, w_vdecay, vth, alpha]
        self.w_scdecay, self.w_vdecay, self.vth, self.alpha = param

    def forward(self, input_data, state, mask, train):
        pre_spike, pre_current, pre_volt = state
        x = self.layer(input_data)
        x = self.bn(x)
        x = torch.relu(x)
        if train:
            x = x * mask
        current = self.w_scdecay * pre_current + x
        volt    = self.w_vdecay  * pre_volt  * (1. - pre_spike) + current
        # pass alpha instead of cw
        output = self.surrogate(volt, self.vth, self.alpha)
        return output, (output, current, volt)


class Wafer2Spike(nn.Module):
    def __init__(self, numClasses, dropout_fc, spike_ts, device, params):
        super(Wafer2Spike, self).__init__()
        self.device     = device
        self.spike_ts   = spike_ts
        self.dropout_fc = dropout_fc
        # params = [scdecay, vdecay, vth, alpha]
        self.scdecay, self.vdecay, self.vth, self.alpha = params

 # Conv layers + GroupNorm
        conv_enc = nn.Conv2d(1,  64, 7, stride=1, bias=True).to(device)
        gn_enc   = nn.GroupNorm(num_groups=8, num_channels=64).to(device)

        conv1    = nn.Conv2d(64, 64, 7, stride=2, bias=True).to(device)
        gn1      = nn.GroupNorm(num_groups=8, num_channels=64).to(device)

        conv2    = nn.Conv2d(64, 64, 7, stride=2, bias=True).to(device)
        gn2      = nn.GroupNorm(num_groups=8, num_channels=64).to(device)

        # FC + GroupNorm
        fc_lin   = nn.Linear(64*9, 256*9, bias=True).to(device)
        gn_fc    = nn.GroupNorm(num_groups=32, num_channels=256*9).to(device)

        # LIF modules
        self.conv_spk_enc = CurrentBasedLIF(
            conv_or_linear=conv_enc,
            bn_layer=gn_enc,           # <- 여기
            surrogate=FastSigmoidSurrogate,
            param=params
        )
        self.Spk_conv1 = CurrentBasedLIF(
            conv_or_linear=conv1,
            bn_layer=gn1,              # <- 여기
            surrogate=FastSigmoidSurrogate,
            param=params
        )
        self.Spk_conv2 = CurrentBasedLIF(
            conv_or_linear=conv2,
            bn_layer=gn2,              # <- 여기
            surrogate=FastSigmoidSurrogate,
            param=params
        )
        self.Spk_fc = CurrentBasedLIFWithDropout(
            linear=fc_lin,
            bn_layer=gn_fc,            # <- 여기
            surrogate=FastSigmoidSurrogate,
            param=params
        )

        # time-dependent weights
        self.w_t = nn.Parameter(torch.ones(self.spike_ts, device=device) / self.spike_ts)
        self.nonSpk_fc = nn.Linear(256*9, numClasses).to(device)

    def forward(self, input_data, states=None):
        batch = input_data.size(0)
        if states is None:
            states = []
            for dims in [(64,30,30), (64,12,12), (64,3,3), (256*9,)]:
                states.append(tuple(torch.zeros(batch, *dims, device=self.device) for _ in range(3)))

        mask_fc = Bernoulli(
            torch.full((batch, 256*9), 1 - self.dropout_fc, device=self.device)
        ).sample() / (1 - self.dropout_fc)

        conv_s, c1_s, c2_s, fc_s = states
        outputs = []
        for t in range(self.spike_ts):
            x, conv_s = self.conv_spk_enc(input_data, conv_s)
            x, c1_s   = self.Spk_conv1(x, c1_s)
            x, c2_s   = self.Spk_conv2(x, c2_s)
            flat      = x.view(batch, -1)
            x, fc_s   = self.Spk_fc(flat, fc_s, mask_fc, self.training)
            out       = self.nonSpk_fc(x) * self.w_t[t]
            outputs.append(out)

        return torch.stack(outputs).sum(0)


class CurrentBasedSNN(nn.Module):
    def __init__(self, numClasses, dropout_fc, spike_ts, device, params):
        super(CurrentBasedSNN, self).__init__()
        self.wafer2spike = Wafer2Spike(numClasses, dropout_fc, spike_ts, device, params)

    def forward(self, input_data):
        # Wafer2Spike가 내부에서 상태 초기화를 처리
        return self.wafer2spike(input_data)

# ─── Cell 3: 학습 함수 정의 및 모델 훈련 ───
import torch
import torch.nn as nn
import numpy as np
from torch.optim.lr_scheduler import ReduceLROnPlateau
from sklearn.metrics import confusion_matrix, classification_report

def test_accuracy(model, loader, criterion, device, phase="Validation"):
    model.eval()
    loss_sum, correct = 0.0, 0
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            out = model(x)
            loss_sum += criterion(out, y).item() * x.size(0)
            correct  += (out.argmax(1) == y).sum().item()
    avg_loss = loss_sum / len(loader.dataset)
    acc      = correct  / len(loader.dataset)
    print(f"{phase} Loss: {avg_loss:.4f}, {phase} Acc: {acc:.4f}")
    model.train()
    return acc

def training(network,
             params,
             dataloaders,
             spike_ts     = 10,    # <<< 여기를 int 로 받습니다
             batch_size   = 256,
             epochs       = 20,
             lr           = 1e-4,
             dropout_fc   = 0.20,
             weight_decay = 1e-5,
             alpha_wd     = 0.0,
             patience_lr  = 2,
             patience_es  = 3):

    train_loader, val_loader, test_loader = dataloaders
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # 1) 모델 인스턴스화
    model = network(
    9,               # num_classes
    dropout_fc,      # dropout_fc
    spike_ts,        # spike_ts
    device,          # device
    params           # params
    )
    model = nn.DataParallel(model.to(device))

    # 2) 클래스 가중치
    all_labels = torch.cat([y for _, y in train_loader], dim=0).cpu().numpy()
    counts = np.bincount(all_labels, minlength=9)
    wts = 1.0 / counts
    wts = wts / wts.sum() * 9
    weight_tensor = torch.tensor(wts, dtype=torch.float32, device=device)
    criterion = nn.CrossEntropyLoss(weight=weight_tensor)

    # 3) Optimizer
    thr_params   = [p for n,p in model.named_parameters() if 'w_t' in n]
    other_params = [p for n,p in model.named_parameters() if 'w_t' not in n]
    optimizer = torch.optim.Adam([
        {'params': other_params, 'weight_decay': weight_decay},
        {'params': thr_params,   'weight_decay': alpha_wd}
    ], lr=lr)

    # 4) Scheduler & EarlyStopping
    scheduler = ReduceLROnPlateau(optimizer, mode='max',
                                  factor=0.5, patience=patience_lr,
                                  verbose=True)
    best_val_acc, es_count = 0.0, 0

    # 5) 학습 루프
    for epoch in range(1, epochs+1):
        model.train()
        tr_loss, tr_corr = 0.0, 0
        for x, y in train_loader:
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            out  = model(x)
            loss = criterion(out, y)
            loss.backward()
            optimizer.step()
            tr_loss += loss.item() * x.size(0)
            tr_corr += (out.argmax(1) == y).sum().item()

        tr_loss /= len(train_loader.dataset)
        tr_acc   = tr_corr / len(train_loader.dataset)
        print(f"Epoch {epoch}/{epochs} — Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}")

        val_acc = test_accuracy(model, val_loader, criterion, device, phase="Validation")
        scheduler.step(val_acc)
        if val_acc > best_val_acc:
            best_val_acc, es_count = val_acc, 0
        else:
            es_count += 1
            if es_count >= patience_es:
                print(f"Early stopping at epoch {epoch}, best val_acc={best_val_acc:.4f}")
                break

    # 6) 최종 Test 평가
    test_acc = test_accuracy(model, test_loader, criterion, device, phase="Test")

    # 7) Confusion Matrix & Report
    all_preds, all_trues = [], []
    model.eval()
    with torch.no_grad():
        for x, y in test_loader:
            x, y = x.to(device), y.to(device)
            preds = model(x).argmax(1)
            all_preds.extend(preds.cpu().tolist())
            all_trues.extend(y.cpu().tolist())

    print("\nConfusion Matrix:")
    print(confusion_matrix(all_trues, all_preds))
    print("\nClassification Report:")
    print(classification_report(all_trues, all_preds, digits=4))

    return model

#  학습 실행 예시
trained_model = training(
    network      = CurrentBasedSNN,
    params       = [0.05, 0.10, 0.08, 5.0],  # [scDecay, vDecay, vTh, alpha]
    dataloaders  = dataloaders,
    spike_ts     = 10,       # <<< 반드시 int!
    batch_size   = 256,
    epochs       = 20,
    lr           = 1e-4,
    dropout_fc   = 0.20,
    weight_decay = 1e-5,
    alpha_wd     = 0.0,
    patience_lr  = 2,
    patience_es  = 3
)

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score

def run_experiment(group_count, lr, dropout_rate, epochs=10, device='cuda'):
    # 모델 정의
    model = CurrentBasedSNN(9, dropout_rate, spike_ts=10, device=device,
                            params=[0.05, 0.10, 0.08, 5.0])
    # GroupNorm 그룹 수 조정
    for module in model.wafer2spike.modules():
        if isinstance(module, nn.GroupNorm):
            module.num_groups = group_count

    model = nn.DataParallel(model).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    # 학습
    for epoch in range(epochs):
        model.train()
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            out = model(xb)
            loss = criterion(out, yb)
            loss.backward()
            optimizer.step()

    # 검증 정확도 계산
    model.eval()
    preds, trues = [], []
    with torch.no_grad():
        for xb, yb in val_loader:
            xb = xb.to(device)
            out = model(xb).argmax(1).cpu().numpy()
            preds.extend(out)
            trues.extend(yb.numpy())
    acc = accuracy_score(trues, preds)
    return acc

# 하이퍼파라미터 그리드
group_counts = [8, 16]
learning_rates = [1e-4, 1e-3]
dropout_rates = [0.3, 0.2]

results = []
for g in group_counts:
    for lr in learning_rates:
        for d in dropout_rates:
            acc = run_experiment(g, lr, d)
            results.append({'groups': g, 'lr': lr, 'dropout': d, 'val_acc': acc})
            print(f"groups={g}, lr={lr}, dropout={d} -> acc={acc:.4f}")

df_results = pd.DataFrame(results)
print(df_results)

import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score, classification_report

# 가정: CurrentBasedSNN, train_loader, val_loader, test_loader 정의됨
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 최적 하이퍼파라미터
best_groups  = 8
best_lr      = 1e-4
best_dropout = 0.3
num_epochs   = 10

# 1) 모델 인스턴스화
model = CurrentBasedSNN(9, best_dropout, spike_ts=10, device=device,
                        params=[0.05, 0.10, 0.08, 5.0])
# GroupNorm 그룹 수 조정
for module in model.wafer2spike.modules():
    if isinstance(module, nn.GroupNorm):
        module.num_groups = best_groups

model = nn.DataParallel(model).to(device)

# 2) 옵티마이저 및 손실함수
optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)
criterion = nn.CrossEntropyLoss()

# 3) 학습
for epoch in range(1, num_epochs+1):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

# 4) 테스트 평가
model.eval()
preds, trues = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb, yb = xb.to(device), yb.to(device)
        pred = model(xb).argmax(dim=1)
        preds.extend(pred.cpu().numpy())
        trues.extend(yb.cpu().numpy())

print("▶️ Test Classification Report:")
print(classification_report(trues, preds, digits=4))

#timestep 10 -> 9 로 변경.

import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score, classification_report

# 가정: CurrentBasedSNN, train_loader, val_loader, test_loader 정의됨
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 최적 하이퍼파라미터
best_groups  = 8
best_lr      = 1e-4
best_dropout = 0.3
num_epochs   = 10

# 1) 모델 인스턴스화
model = CurrentBasedSNN(9, best_dropout, spike_ts=9, device=device,
                        params=[0.05, 0.10, 0.08, 5.0])
# GroupNorm 그룹 수 조정
for module in model.wafer2spike.modules():
    if isinstance(module, nn.GroupNorm):
        module.num_groups = best_groups

model = nn.DataParallel(model).to(device)

# 2) 옵티마이저 및 손실함수
optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)
criterion = nn.CrossEntropyLoss()

# 3) 학습
for epoch in range(1, num_epochs+1):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

# 4) 테스트 평가
model.eval()
preds, trues = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb, yb = xb.to(device), yb.to(device)
        pred = model(xb).argmax(dim=1)
        preds.extend(pred.cpu().numpy())
        trues.extend(yb.cpu().numpy())

print("▶️ Test Classification Report:")
print(classification_report(trues, preds, digits=4))

#timestep 10 -> 8 로 변경.

import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score, classification_report

# 가정: CurrentBasedSNN, train_loader, val_loader, test_loader 정의됨
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 최적 하이퍼파라미터
best_groups  = 8
best_lr      = 1e-4
best_dropout = 0.3
num_epochs   = 10

# 1) 모델 인스턴스화
model = CurrentBasedSNN(9, best_dropout, spike_ts=8, device=device,
                        params=[0.05, 0.10, 0.08, 5.0])
# GroupNorm 그룹 수 조정
for module in model.wafer2spike.modules():
    if isinstance(module, nn.GroupNorm):
        module.num_groups = best_groups

model = nn.DataParallel(model).to(device)

# 2) 옵티마이저 및 손실함수
optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)
criterion = nn.CrossEntropyLoss()

# 3) 학습
for epoch in range(1, num_epochs+1):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

# 4) 테스트 평가
model.eval()
preds, trues = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb, yb = xb.to(device), yb.to(device)
        pred = model(xb).argmax(dim=1)
        preds.extend(pred.cpu().numpy())
        trues.extend(yb.cpu().numpy())

print("▶️ Test Classification Report:")
print(classification_report(trues, preds, digits=4))

#timestep 10 -> 7 로 변경.

import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score, classification_report

# 가정: CurrentBasedSNN, train_loader, val_loader, test_loader 정의됨
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 최적 하이퍼파라미터
best_groups  = 8
best_lr      = 1e-4
best_dropout = 0.3
num_epochs   = 10

# 1) 모델 인스턴스화
model = CurrentBasedSNN(9, best_dropout, spike_ts=7, device=device,
                        params=[0.05, 0.10, 0.08, 5.0])
# GroupNorm 그룹 수 조정
for module in model.wafer2spike.modules():
    if isinstance(module, nn.GroupNorm):
        module.num_groups = best_groups

model = nn.DataParallel(model).to(device)

# 2) 옵티마이저 및 손실함수
optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)
criterion = nn.CrossEntropyLoss()

# 3) 학습
for epoch in range(1, num_epochs+1):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

# 4) 테스트 평가
model.eval()
preds, trues = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb, yb = xb.to(device), yb.to(device)
        pred = model(xb).argmax(dim=1)
        preds.extend(pred.cpu().numpy())
        trues.extend(yb.cpu().numpy())

print("▶️ Test Classification Report:")
print(classification_report(trues, preds, digits=4))

#timestep 10 -> 5 로 변경.

import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score, classification_report

# 가정: CurrentBasedSNN, train_loader, val_loader, test_loader 정의됨
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 최적 하이퍼파라미터
best_groups  = 8
best_lr      = 1e-4
best_dropout = 0.3
num_epochs   = 10

# 1) 모델 인스턴스화
model = CurrentBasedSNN(9, best_dropout, spike_ts=5, device=device,
                        params=[0.05, 0.10, 0.08, 5.0])
# GroupNorm 그룹 수 조정
for module in model.wafer2spike.modules():
    if isinstance(module, nn.GroupNorm):
        module.num_groups = best_groups

model = nn.DataParallel(model).to(device)

# 2) 옵티마이저 및 손실함수
optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)
criterion = nn.CrossEntropyLoss()

# 3) 학습
for epoch in range(1, num_epochs+1):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()

# 4) 테스트 평가
model.eval()
preds, trues = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb, yb = xb.to(device), yb.to(device)
        pred = model(xb).argmax(dim=1)
        preds.extend(pred.cpu().numpy())
        trues.extend(yb.cpu().numpy())

print("▶️ Test Classification Report:")
print(classification_report(trues, preds, digits=4))

# DataParallel 래퍼 해제
model = trained_model.module if hasattr(trained_model, 'module') else trained_model

# ─── Cell 5: forward()만 떼서 전력 측정 ───
import time
import pynvml
import torch
from IPython.display import display

# 1) NVML 초기화 & 파워 리더 함수
pynvml.nvmlInit()
_handle = pynvml.nvmlDeviceGetHandleByIndex(0)
def get_gpu_power():
    return pynvml.nvmlDeviceGetPowerUsage(_handle) / 1000.0  # mW → W

device = next(model.parameters()).device  # 모델이 올라간 디바이스

# 2) 한 배치만 뽑아서 미리 GPU에 올려두기
batch, _ = next(iter(test_loader))
batch = batch.to(device, non_blocking=True)

# 3) idle baseline 전력 측정 (GPU 연산 대기 상태)
idle_samples = []
for _ in range(20):         # 20번 샘플링
    idle_samples.append(get_gpu_power())
    time.sleep(0.01)        # 10ms 간격
idle_power = sum(idle_samples) / len(idle_samples)

# 4) forward 전/후 전력 샘플링
torch.cuda.synchronize()
p0 = get_gpu_power()
t0 = time.time()

# 순수 연산
_ = model(batch)

torch.cuda.synchronize()
t1 = time.time()
p1 = get_gpu_power()

# 5) 에너지 계산 (W·s → J)
energy = ((p0 + p1)/2 - idle_power) * (t1 - t0)
print(f"한 배치({batch.size(0)}개) 순수 forward 에너지: {energy:.6f} J")

# 6) 샘플당 에너지
per_sample = energy / batch.size(0)
print(f"샘플당 에너지: {per_sample*1e3:.3f} mJ")

# 7) 결과 표시
print(f"  p0={p0:.3f} W, p1={p1:.3f} W, idle={idle_power:.3f} W, Δt={t1-t0:.4f} s")

# Commented out IPython magic to ensure Python compatibility.
# #Idle 전력 측정 (idle_duration 동안 주기적으로 전력 측정 후 평균)
# #순수 추론 전력 계산: 측정된 전력에서 idle 평균을 빼고 적분
# %%bash
# cat << 'EOF' > gpu_power_measurement.py
# import time
# import torch
# import pynvml
# import pandas as pd
# from torch.utils.data import DataLoader
# from typing import Tuple
# 
# pynvml.nvmlInit()
# _handle = pynvml.nvmlDeviceGetHandleByIndex(0)
# 
# def get_gpu_power() -> float:
#     return pynvml.nvmlDeviceGetPowerUsage(_handle) / 1000.0
# 
# def measure_inference_power(
#     model: torch.nn.Module,
#     dataloader: DataLoader,
#     device: str = 'cuda',
#     idle_duration: float = 1.0,
#     sample_interval: float = 0.05
# ) -> Tuple[float, pd.DataFrame]:
#     # 1) Idle 전력 측정
#     idle_samples = []
#     t0 = time.time()
#     while time.time() - t0 < idle_duration:
#         idle_samples.append(get_gpu_power())
#         time.sleep(sample_interval)
#     idle_power = sum(idle_samples) / len(idle_samples)
# 
#     # 2) 추론 중 전력 측정
#     model.eval().to(device)
#     timestamps, raw_powers = [], []
#     t_start = time.time()
#     t_next = t_start
# 
#     with torch.no_grad():
#         for xb, _ in dataloader:
#             xb = xb.to(device)
#             now = time.time()
#             if now >= t_next:
#                 timestamps.append(now - t_start)
#                 raw_powers.append(get_gpu_power())
#                 t_next += sample_interval
#             _ = model(xb)
# 
#     t_end = time.time()
#     timestamps.append(t_end - t_start)
#     raw_powers.append(get_gpu_power())
# 
#     # 3) Idle 보정 및 에너지 적분
#     corrected = [p - idle_power for p in raw_powers]
#     energy = 0.0
#     for i in range(len(corrected)-1):
#         dt = timestamps[i+1] - timestamps[i]
#         energy += max((corrected[i] + corrected[i+1]) / 2, 0.0) * dt
# 
#     log_df = pd.DataFrame({
#         'time_s': timestamps,
#         'raw_power_W': raw_powers,
#         'idle_power_W': idle_power,
#         'corrected_power_W': corrected
#     })
# 
#     return energy, log_df
# EOF

from gpu_power_measurement import measure_inference_power

# model, test_loader 준비 후
energy, log_df = measure_inference_power(model, test_loader)
print(f"▶️ 순수 추론 에너지: {energy:.3f} J")
display(log_df.head())

import torch
!pip install torchviz graphviz
from torchviz import make_dot

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = CurrentBasedSNN(N_CLASSES, DROPOUT_FC, SPIKE_TS, device, params=[0.1,0.1,0.1,0.3])
model = nn.DataParallel(model).to(device)
model.eval()

# 더미 입력 한 배치
x = torch.randn(1,1,36,36, device=device)
y = model(x)

# 계산 그래프를 DOT 포맷으로 생성
dot = make_dot(y, params=dict(model.named_parameters()))
dot.format = 'png'
dot.render('snn_model_graph')  # SNN 구조가 snn_model_graph.png 로 저장

from IPython.display import Image, display
display(Image(filename='snn_model_graph.png'))
dot.render(filename='/mnt/data/snn_model_graph', format='png')

from google.colab import files
files.download('/content/snn_model_graph.png')